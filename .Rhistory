plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
mod_rf <- read_rds("Data/Output/RDS_data/rf_midsized.rds")
mod_rf <- read_rds("Data/Output/RDS_data/rf_midsized.rds")
vip <-
vip(mod_rf, # Machine learning model
train = train_data_processed, # Training data
method="permute", # permuted importance
nsim = 10, # number of times to impute
geom = "boxplot", # Type of plot
target = "evictions", # outcome
reference_class = "Above_average",
metric = "accuracy",
pred_wrapper = predict)
vip +
labs(title = "Mid-sized Variable Importance",
y = "") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 20,
family = "serif"),
text = element_text(family = "serif",
size = 16),
legend.position="right")
ggsave("Plots/VIP/midsized.png", width = 10)
write_rds(vip, "Data/Output/RDS_data/midsized_vip.rds")
vi_table <-
vip$data
write_csv(vi_table, "Data/Output/CSV_data/midsized_variable_importance.csv")
most_imp_vars <- vi_table %>%
select(Variable) %>%
pull()
# Plot the partial dependence plots
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Mid-sized")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
mod_rf <- read_rds("Data/Output/RDS_data/rf_exurban.rds")
mod_rf <- read_rds("Data/Output/RDS_data/rf_exurban.rds")
vip <-
vip(mod_rf, # Machine learning model
train = train_data_processed, # Training data
method="permute", # permuted importance
nsim = 10, # number of times to impute
geom = "boxplot", # Type of plot
target = "evictions", # outcome
reference_class = "Above_average",
metric = "accuracy",
pred_wrapper = predict)
vip +
labs(title = "Exurban Variable Importance",
y = "") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 20,
family = "serif"),
text = element_text(family = "serif",
size = 16),
legend.position="right")
ggsave("Plots/VIP/exurban.png", width = 10)
write_rds(vip, "Data/Output/RDS_data/exurban_vip.rds")
vi_table <-
vip$data
write_csv(vi_table, "Data/Output/CSV_data/exurban_variable_importance.csv")
most_imp_vars <- vi_table %>%
select(Variable) %>%
pull()
# Plot the partial dependence plots
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Exurban")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
mod_rf <- read_rds("Data/Output/RDS_data/rf_metro.rds")
vip <-
vip(mod_rf, # Machine learning model
train = train_data_processed, # Training data
method="permute", # permuted importance
nsim = 10, # number of times to impute
geom = "boxplot", # Type of plot
target = "evictions", # outcome
reference_class = "Above_average",
metric = "accuracy",
pred_wrapper = predict)
vip +
labs(title = "Metro Variable Importance",
y = "") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 20,
family = "serif"),
text = element_text(family = "serif",
size = 16),
legend.position="right")
ggsave("Plots/VIP/metro.png", width = 10)
write_rds(vip, "Data/Output/RDS_data/metro_vip.rds")
vi_table <-
vip$data
write_csv(vi_table, "Data/Output/CSV_data/metro_variable_importance.csv")
most_imp_vars <- vi_table %>%
select(Variable) %>%
pull()
# Plot the partial dependence plots
plots <- list()
do.call("grid.arrange", c(plots, ncol=2))
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Exurban")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Metro")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
mod_rf <- read_rds("Data/Output/RDS_data/rf_poploss.rds")
vip <-
vip(mod_rf, # Machine learning model
train = train_data_processed, # Training data
method="permute", # permuted importance
nsim = 10, # number of times to impute
geom = "boxplot", # Type of plot
target = "evictions", # outcome
reference_class = "Above_average",
metric = "accuracy",
pred_wrapper = predict)
vip +
labs(title = "Poploss Variable Importance",
y = "") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 20,
family = "serif"),
text = element_text(family = "serif",
size = 16),
legend.position="right")
ggsave("Plots/VIP/poploss.png", width = 10)
write_rds(vip, "Data/Output/RDS_data/poploss_vip.rds")
vi_table <-
vip$data
write_csv(vi_table, "Data/Output/CSV_data/poploss_variable_importance.csv")
most_imp_vars <- vi_table %>%
select(Variable) %>%
pull()
# Plot the partial dependence plots
plots <- list()
do.call("grid.arrange", c(plots, ncol=2))
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Poploss")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
mod_rf <- read_rds("Data/Output/RDS_data/rf_rentburdened.rds")
mod_rf <- read_rds("Data/Output/RDS_data/rf_rentburden.rds")
vip <-
vip(mod_rf, # Machine learning model
train = train_data_processed, # Training data
method="permute", # permuted importance
nsim = 10, # number of times to impute
geom = "boxplot", # Type of plot
target = "evictions", # outcome
reference_class = "Above_average",
metric = "accuracy",
pred_wrapper = predict)
vip +
labs(title = "Rent Burden Variable Importance",
y = "") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 20,
family = "serif"),
text = element_text(family = "serif",
size = 16),
legend.position="right")
ggsave("Plots/VIP/rentburden.png", width = 10)
write_rds(vip, "Data/Output/RDS_data/rentburden_vip.rds")
vi_table <-
vip$data
write_csv(vi_table, "Data/Output/CSV_data/rentburden_variable_importance.csv")
most_imp_vars <- vi_table %>%
select(Variable) %>%
pull()
# Plot the partial dependence plots
plots <- list()
for(i in seq_along(most_imp_vars)){
pdp <- partial(mod_rf, pred.var = most_imp_vars[i], plot = TRUE, prob=T,
grid.resolution = 20,
plot.engine = "ggplot2") +
geom_line(color = "#de4815") +
theme_minimal() +
theme(plot.title=element_text(hjust = 0.5,
size = 16,
family = "serif"),
text = element_text(family = "serif",
size = 12),
legend.position="right") +
labs(y = "Rent Burden")
plots[[i]] <- pdp
}
do.call("grid.arrange", c(plots, ncol=2))
sendmail("izzyoungs@gmail.com", subject="Notification from R", message="Conditions finished running!")
library(here)
library(tidyverse)
library(vip)
library(gridExtra)
library(pdp)
library(parallel)
library(doParallel)
library(rsample)
library(yardstick)
library(recipes)
library(mail)
sendmail("izzyoungs@gmail.com", subject="Notification from R", message="Conditions finished running!")
alarm()
install.packages("beepr")
library(beepr)
beep()
mod_rf <- read_rds("Data/Output/RDS_data/rf_all.rds")
vip_rent_burden <- vi_permute(mod_rf, # Machine learning model
train = train_data_processed %>% mutate(d_rent_burdened_X1=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "evictions", # outcome
reference_class = "Above_average", # what class are you predicting
metric = "auc", # metric
pred_wrapper = predict) # prediction function
beep()
library(here)
library(tidyverse)
library(caret)
library(parallel)
library(doParallel)
library(rsample)
library(yardstick)
library(recipes)
set.seed(1992) # Ensure reproducibility
# Read in the data
evictions_data <-read_csv("Data/Output/final_frame.csv") %>%
mutate_if(is.character, as.factor) %>%
mutate_at(vars(starts_with("d_")), as.factor) %>%
mutate(year = as.factor(year)) %>%
select(-1, -3:-8)
# We will only be using the eviction filing rate categorical variable
ind_var <- "d_above_avg_eviction_rate"
# We will not be using the continuous or eviction rates variable
rm_var <- c("eviction_rate",
"eviction_filing_rate",
"delta_eviction_rates",
"d_above_avg_eviction_filing_rate")
evictions_cleaned <- evictions_data %>%
# Select all columns and remove vars we won't use
select(evictions = all_of(ind_var), everything(), -all_of(rm_var)) %>%
# Rename variables so they are not dummy variables
mutate(evictions = as.factor(ifelse(evictions == 0, "Below_Average", "Above_Average")))
# Stratify and split the data ---------------------------------------------
# Make sure the class is equal in each split
strata <- "evictions"
# Create a function that splits the data into three objects
splitting <- function(dat){
# Create the split for counties
split <- initial_split(dat, prop = .8, strata = all_of(strata))
test_data  <<- testing(split)
train_data <<- training(split)
}
# Create test, train, and validation objects
splitting(evictions_cleaned)
# Preprocess data ---------------------------------------------------------
# Initialize our recipe
our_recipe <- recipe(evictions ~ ., data = train_data) %>%
step_knnimpute(all_nominal()) %>%
step_knnimpute(all_numeric()) %>%
step_log(all_numeric(), signed = TRUE) %>%
step_dummy(all_nominal(), -evictions, -geoid) %>%
prep() %>% suppressMessages()
# Apply the recipe to the training and test data
train_data_processed <- suppressMessages(bake(our_recipe,train_data))
test_data_processed <- suppressMessages(bake(our_recipe,test_data))
write_csv(train_data_processed, "Data/Output/CSV_data/train_data_processed.csv")
train_data_processed <- read_csv("Data/Output/CSV_data/train_data_processed.csv")
library(here)
library(tidyverse)
library(vip)
library(gridExtra)
library(pdp)
library(parallel)
library(doParallel)
library(rsample)
library(yardstick)
library(recipes)
library(beepr)
# Variable importance assessment ------------------------------------------
mod_rf <- read_rds("Data/Output/RDS_data/rf_all.rds")
train_data_processed <- read_csv("Data/Output/CSV_data/train_data_processed.csv")
vip_rent_burden <- vi_permute(mod_rf, # Machine learning model
train = train_data_processed %>% mutate(d_rent_burdened_X1=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "evictions", # outcome
reference_class = "Above_average", # what class are you predicting
metric = "auc", # metric
pred_wrapper = predict) # prediction function
beep()
vip_rent_burden
mod_rf
train_data_processed %>% mutate(d_rent_burdened_X1=1)
vip_rent_burden
vip_rent_burden %>% view
D
train_data_processed %>% select(evictions) %>% glimpse
require(tidyverse)
require(caret)
require(pdp)
require(vip)
# Simulate some data  -----------------------------------------------------
set.seed(123)
N = 1000 # Number of observations
x1 <- rnorm(N) # independent variable
x2 <- rnorm(N) # independent variable
rural <- rbinom(N,1,.3) # Urban-rural dummy
error <- rnorm(N) #  error
# Class outcome
y <-  ifelse(1 + 5*x1 + -2*x2 + -2*x2*rural + -3*rural > error,"yes","no") # dependent variable as a function of covars
D <- tibble(y,x1,x2,rural) # Gather as data frame
D
# Model ---------------------
# Cross fold validation
set.seed(1988)
folds <- createFolds(D$y, k = 5)
control_conditions <-
trainControl(method='cv',
summaryFunction = twoClassSummary,
classProbs = TRUE,
index = folds )
# Random Forest Model
rf_model <-train(y ~ ., data=D,
method = "ranger", metric = "ROC",
trControl = control_conditions)
# Interpret ---------------------
# Variable importance example
vip_rural = vi_permute(rf_model, # Machine learning model
train = D %>% mutate(rural=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "y", # outcome
reference_class = "yes", # what class are you predicting
metric = "auc", # metric
pred_wrapper = predict) # prediction function
vip_rural
# Interpret ---------------------
# Variable importance example
vip_rural = vi_permute(rf_model, # Machine learning model
train = D %>% mutate(rural=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "y", # outcome
reference_class = "yes", # what class are you predicting
metric = "accuracy", # metric
pred_wrapper = predict) # prediction function
vip_rural
# Interpret ---------------------
# Variable importance example
vip_rural = vi_permute(rf_model, # Machine learning model
train = D %>% mutate(rural=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "y", # outcome
reference_class = "yes", # what class are you predicting
metric = "auc", # metric
pred_wrapper = predict) # prediction function
vip_rural
train_data_processed %>% mutate(d_rent_burdened_X1=1) %>% glimpse
vip_rent_burden
train_data_processed$d_rent_burdened_X1
mod_rf
D
train_data_processed$evictions
# Random Forest Model
mod_rf <-
train(evictions ~ . -geoid,
data=train_data_processed,
method = "ranger",
metric = "ROC",
num.trees = 100,
trControl = control_conditions)
mod_rf
set.seed(1992) # Ensure reproducibility
# Read in the data
evictions_data <-read_csv("Data/Output/final_frame.csv") %>%
mutate_if(is.character, as.factor) %>%
mutate_at(vars(starts_with("d_")), as.factor) %>%
mutate(year = as.factor(year)) %>%
select(-1, -3:-8)
# We will only be using the eviction filing rate categorical variable
ind_var <- "d_above_avg_eviction_rate"
# We will not be using the continuous or eviction rates variable
rm_var <- c("eviction_rate",
"eviction_filing_rate",
"delta_eviction_rates",
"d_above_avg_eviction_filing_rate")
evictions_cleaned <- evictions_data %>%
# Select all columns and remove vars we won't use
select(evictions = all_of(ind_var), everything(), -all_of(rm_var)) %>%
# Rename variables so they are not dummy variables
mutate(evictions = as.factor(ifelse(evictions == 0, "Below_Average", "Above_Average")))
# Stratify and split the data ---------------------------------------------
# Make sure the class is equal in each split
strata <- "evictions"
# Create a function that splits the data into three objects
splitting <- function(dat){
# Create the split for counties
split <- initial_split(dat, prop = .8, strata = all_of(strata))
test_data  <<- testing(split)
train_data <<- training(split)
}
# Create test, train, and validation objects
splitting(evictions_cleaned)
# Preprocess data ---------------------------------------------------------
# Initialize our recipe
our_recipe <- recipe(evictions ~ ., data = train_data) %>%
step_knnimpute(all_nominal()) %>%
step_knnimpute(all_numeric()) %>%
step_log(all_numeric(), signed = TRUE) %>%
step_dummy(all_nominal(), -evictions, -geoid) %>%
prep() %>% suppressMessages()
# Apply the recipe to the training and test data
train_data_processed <- suppressMessages(bake(our_recipe,train_data))
test_data_processed <- suppressMessages(bake(our_recipe,test_data))
write_csv(train_data_processed, "Data/Output/CSV_data/train_data_processed.csv")
# Partition the data into 5 folds
folds <- createFolds(train_data_processed$evictions, k = 5)
# Cross validation settings as an object
control_conditions <-
trainControl(method='cv',
summaryFunction = twoClassSummary,
classProbs = TRUE,
sampling = "up",
index = folds)
# Random Forest Model
mod_rf <-
train(evictions ~ . -geoid,
data=train_data_processed,
method = "ranger",
metric = "ROC",
num.trees = 100,
trControl = control_conditions)
mod_rf
vip_rent_burden <- vi_permute(mod_rf, # Machine learning model
train = train_data_processed %>% mutate(d_rent_burdened_X1=1), # Training data
nsim = 10, # Number of times to permute each variable
target = "evictions", # outcome
reference_class = "Above_average", # what class are you predicting
metric = "auc", # metric
pred_wrapper = predict) # prediction function
beep()
vip_rent_burden
